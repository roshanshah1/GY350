{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dict of file name and api keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base URL and parameters\n",
    "base_url_profile = \"https://api.census.gov/data/{year}/acs/acs5/profile?get=group({group})&for=tract:*&in=state:{state}\"\n",
    "base_url_subject = \"https://api.census.gov/data/{year}/acs/acs5/subject?get=NAME,group({group})&for=tract:*&in=state:{state}\"\n",
    "\n",
    "years = list(range(2010, 2024))  # From 2010 to 2023\n",
    "states = [\"06\", \"32\"]  # State codes as strings to preserve leading zeros\n",
    "categories = {\n",
    "    \"DP03\": \"profile\",\n",
    "    \"DP05\": \"profile\",\n",
    "    \"S1501\": \"subject\",\n",
    "    \"S2506\": \"subject\"\n",
    "}\n",
    "\n",
    "data_links = {}\n",
    "\n",
    "# Generate URLs using nested loops\n",
    "for group, category in categories.items():\n",
    "    for state in states:\n",
    "        for year in years:\n",
    "            key = f\"{group}_{year}_{state}\"\n",
    "            if category == \"profile\":\n",
    "                url = base_url_profile.format(year=year, group=group, state=state)\n",
    "            else:\n",
    "                url = base_url_subject.format(year=year, group=group, state=state)\n",
    "            data_links[key] = url\n",
    "\n",
    "# Print example of generated keys and links\n",
    "for key, link in list(data_links.items())[:5]:\n",
    "    print(f\"{key}: {link}\")  # Previewing first 5 links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Define the save directory\n",
    "save_directory = r\"H:\\GY350\\File Downloads\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over each key-value pair in the dictionary\n",
    "for filename, url in data_links.items():\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON format\n",
    "        \n",
    "        # Define file path\n",
    "        file_path = os.path.join(save_directory, f\"{filename}.csv\")\n",
    "        \n",
    "        # Write data to CSV file\n",
    "        with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(data)\n",
    "        \n",
    "        print(f\"Successfully saved: {filename}.csv\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finish downloading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Define the save directory\n",
    "save_directory = r\"H:\\GY350\\File Downloads\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Identify files that are already downloaded\n",
    "existing_files = set(f for f in os.listdir(save_directory) if f.endswith(\".csv\"))\n",
    "\n",
    "# Define the starting point based on last downloaded file\n",
    "start_downloading = False\n",
    "\n",
    "# Iterate over remaining key-value pairs in the dictionary\n",
    "for filename, url in data_links.items():\n",
    "    expected_filename = f\"{filename}.csv\"\n",
    "    \n",
    "    # Start downloading from S1501_2023_06.csv onwards\n",
    "    if expected_filename == \"S1501_2023_06.csv\":\n",
    "        start_downloading = True\n",
    "        continue  # Skip the last downloaded file itself\n",
    "    \n",
    "    if not start_downloading:\n",
    "        continue  # Skip files until reaching the last downloaded file\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON format\n",
    "        \n",
    "        # Define file path\n",
    "        file_path = os.path.join(save_directory, expected_filename)\n",
    "        \n",
    "        # Write data to CSV file\n",
    "        with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(data)\n",
    "        \n",
    "        print(f\"Successfully saved: {expected_filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {expected_filename}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename files - run after all filed successfully saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the downloaded files\n",
    "directory = r\"H:\\GY350\\File Downloads\"\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):  # Ensure it's a CSV file\n",
    "        parts = filename.rstrip(\".csv\").split(\"_\")\n",
    "        \n",
    "        if len(parts) == 3:  # Ensure correct formatting\n",
    "            new_filename = f\"{parts[0]}_{parts[2]}_{parts[1]}.csv\"\n",
    "            old_path = os.path.join(directory, filename)\n",
    "            new_path = os.path.join(directory, new_filename)\n",
    "            \n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {filename} -> {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create new folder and copy files for manual edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source and destination directories\n",
    "source_directory = r\"H:\\GY350\\File Downloads\"\n",
    "destination_directory = r\"H:\\GY350\\CSV Manual Edits\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# Copy all files from source to destination\n",
    "for filename in os.listdir(source_directory):\n",
    "    source_path = os.path.join(source_directory, filename)\n",
    "    destination_path = os.path.join(destination_directory, filename)\n",
    "    \n",
    "    if os.path.isfile(source_path):  # Ensure it's a file\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename}\")\n",
    "\n",
    "print(\"All files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cancelled due to lack of storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
