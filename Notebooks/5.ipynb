{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for S2506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare all row 1s and find unique header sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1:\n",
      "['S2506_06_2010.csv', 'S2506_32_2010.csv']\n",
      "-\n",
      "Group 2:\n",
      "['S2506_06_2011.csv', 'S2506_06_2012.csv', 'S2506_32_2011.csv', 'S2506_32_2012.csv']\n",
      "-\n",
      "Group 3:\n",
      "['S2506_06_2013.csv', 'S2506_06_2014.csv', 'S2506_32_2013.csv', 'S2506_32_2014.csv']\n",
      "-\n",
      "Group 4:\n",
      "['S2506_06_2015.csv', 'S2506_06_2016.csv', 'S2506_32_2015.csv', 'S2506_32_2016.csv']\n",
      "-\n",
      "Group 5:\n",
      "['S2506_06_2017.csv', 'S2506_06_2018.csv', 'S2506_06_2019.csv', 'S2506_32_2017.csv', 'S2506_32_2018.csv', 'S2506_32_2019.csv']\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory\n",
    "source_dir = r\"H:\\GY350\\File Downloads\"\n",
    "\n",
    "# Dictionary to store unique row ones\n",
    "headers_checked = {}\n",
    "\n",
    "# Iterate over S2506 files\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.startswith(\"S2506\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read only the first row (headers)\n",
    "            df = pd.read_csv(file_path, nrows=1, header=None)\n",
    "            header_signature = tuple(df.iloc[0].dropna())  # Convert row one to tuple for uniqueness\n",
    "            \n",
    "            # Check if the header already exists\n",
    "            if header_signature in headers_checked:\n",
    "                headers_checked[header_signature].append(filename)\n",
    "            else:\n",
    "                headers_checked[header_signature] = [filename]\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Convert to list format\n",
    "file_groups = list(headers_checked.values())\n",
    "\n",
    "# Output results\n",
    "for i, group in enumerate(file_groups, 1):\n",
    "    print(f\"Group {i}:\")\n",
    "    print(group)\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add manually created rows to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:21: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,141,142,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ref = pd.read_csv(reference_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_32_2010.csv with new row from S2506_06_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:21: DtypeWarning: Columns (3,4,5,6,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223,225,227,229,231,233,235,237,239,241,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ref = pd.read_csv(reference_file, header=None)\n",
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:27: DtypeWarning: Columns (3,4,5,6,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223,225,227,229,231,233,235,237,239,241,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_06_2012.csv with new row from S2506_06_2011.csv\n",
      "Updated: S2506_32_2011.csv with new row from S2506_06_2011.csv\n",
      "Updated: S2506_32_2012.csv with new row from S2506_06_2011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:21: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ref = pd.read_csv(reference_file, header=None)\n",
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:27: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_06_2014.csv with new row from S2506_06_2013.csv\n",
      "Updated: S2506_32_2013.csv with new row from S2506_06_2013.csv\n",
      "Updated: S2506_32_2014.csv with new row from S2506_06_2013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:21: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ref = pd.read_csv(reference_file, header=None)\n",
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:27: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_06_2016.csv with new row from S2506_06_2015.csv\n",
      "Updated: S2506_32_2015.csv with new row from S2506_06_2015.csv\n",
      "Updated: S2506_32_2016.csv with new row from S2506_06_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:21: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ref = pd.read_csv(reference_file, header=None)\n",
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:27: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_06_2018.csv with new row from S2506_06_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\2794691257.py:27: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: S2506_06_2019.csv with new row from S2506_06_2017.csv\n",
      "Updated: S2506_32_2017.csv with new row from S2506_06_2017.csv\n",
      "Updated: S2506_32_2018.csv with new row from S2506_06_2017.csv\n",
      "Updated: S2506_32_2019.csv with new row from S2506_06_2017.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory\n",
    "source_dir = r\"H:\\GY350\\File Downloads\"\n",
    "\n",
    "# Groups from previous run\n",
    "file_groups = [\n",
    "    ['S2506_06_2010.csv', 'S2506_32_2010.csv'],\n",
    "    ['S2506_06_2011.csv', 'S2506_06_2012.csv', 'S2506_32_2011.csv', 'S2506_32_2012.csv'],\n",
    "    ['S2506_06_2013.csv', 'S2506_06_2014.csv', 'S2506_32_2013.csv', 'S2506_32_2014.csv'],\n",
    "    ['S2506_06_2015.csv', 'S2506_06_2016.csv', 'S2506_32_2015.csv', 'S2506_32_2016.csv'],\n",
    "    ['S2506_06_2017.csv', 'S2506_06_2018.csv', 'S2506_06_2019.csv', 'S2506_32_2017.csv', 'S2506_32_2018.csv', 'S2506_32_2019.csv']\n",
    "]\n",
    "\n",
    "# Iterate over each group and apply the row copying\n",
    "for group in file_groups:\n",
    "    reference_file = os.path.join(source_dir, group[0])  # First file in the group\n",
    "    \n",
    "    # Read the reference file\n",
    "    df_ref = pd.read_csv(reference_file, header=None)\n",
    "    new_row = df_ref.iloc[1].copy()  # Copy manually added second row\n",
    "    \n",
    "    # Apply to rest of the group\n",
    "    for filename in group[1:]:\n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        \n",
    "        # Insert the copied row as a new second row\n",
    "        df.loc[len(df)] = None  # Create an empty row at the end to shift everything\n",
    "        df = df.sort_index().reset_index(drop=True)  # Reset index to shift rows correctly\n",
    "        df.loc[1] = new_row  # Assign new row to second row\n",
    "        \n",
    "        # Save the updated file\n",
    "        df.to_csv(file_path, index=False, header=False)\n",
    "        print(f\"Updated: {filename} with new row from {group[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove uneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,141,142,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223,225,227,229,231,233,235,237,239,241,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2011.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223,225,227,229,231,233,235,237,239,241,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,279,280,281) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2012.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2013.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2014.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHR49\\AppData\\Local\\Temp\\ipykernel_14956\\1227351979.py:20: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,157,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,261,263,264,265,266,267,269,271,273,275,277,279,281,283,285,287,289,291,293,295,297,299,301,303,305,307,309,311,313,315,317,319,321,323,325,327,329,331,333,335,337,339,341,343,345,347,349,351,353,355,357,359,361,363,365,367,369,371,373,375,377,379,381,383,385,387,389,391,393,395,397,399,401,403,405,407,409,411,413,415,417,419,421,423,425,427,429,431,433,435,437,439,441,443,445,447,449,451,453,455,457,459,461,463,465,467,469,471,473,475,477,479,481,483,485,487,489,491,493,495,497,499,501,503,505,507,509,511,513,515,517,519,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cleaned_df = pd.read_csv(source_file, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_06_2019.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2010.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2011.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2012.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2013.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2014.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2015.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2016.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2017.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2018.csv\n",
      "Cleaned CSV saved at: H:\\GY350\\CSVs Cleaned\\S2506_32_2019.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "source_dir = r\"H:\\GY350\\File Downloads\"\n",
    "destination_dir = r\"H:\\GY350\\CSVs Cleaned\"\n",
    "os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Iterate over S2506 files\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.startswith(\"S2506\") and filename.endswith(\".csv\"):\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "        destination_file = os.path.join(destination_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(source_file):\n",
    "            print(f\"File not found: {source_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Load and process the CSV\n",
    "        cleaned_df = pd.read_csv(source_file, header=None)\n",
    "        \n",
    "        # Identify columns to keep (columns where row 2 has a value)\n",
    "        columns_to_keep = cleaned_df.iloc[1].notna()\n",
    "        \n",
    "        # Drop columns that do not meet the condition\n",
    "        cleaned_df = cleaned_df.loc[:, columns_to_keep]\n",
    "        \n",
    "        # Drop the first row (original row 1)\n",
    "        cleaned_df = cleaned_df.iloc[1:].reset_index(drop=True)\n",
    "        \n",
    "        # Save cleaned CSV\n",
    "        cleaned_df.to_csv(destination_file, index=False, header=False)\n",
    "        \n",
    "        print(f\"Cleaned CSV saved at: {destination_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check all columns present and same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All S2506 files have the same number of columns and column names (regardless of order).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory\n",
    "cleaned_dir = r\"H:\\GY350\\CSVs Cleaned\"\n",
    "\n",
    "# Store column sets\n",
    "column_sets = {}\n",
    "num_columns = {}\n",
    "\n",
    "# Iterate over S2506 files\n",
    "for filename in os.listdir(cleaned_dir):\n",
    "    if filename.startswith(\"S2506\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(cleaned_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            columns_set = set(df.columns)\n",
    "            num_cols = len(df.columns)\n",
    "            \n",
    "            # Store column details\n",
    "            column_sets[filename] = columns_set\n",
    "            num_columns[filename] = num_cols\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Check for column consistency\n",
    "reference_file = next(iter(column_sets))  # Pick first file as reference\n",
    "reference_columns = column_sets[reference_file]\n",
    "reference_num_cols = num_columns[reference_file]\n",
    "\n",
    "consistent = True\n",
    "for filename, col_set in column_sets.items():\n",
    "    if col_set != reference_columns:\n",
    "        print(f\"Column mismatch in {filename}\")\n",
    "        consistent = False\n",
    "    if num_columns[filename] != reference_num_cols:\n",
    "        print(f\"Column count mismatch in {filename}: {num_columns[filename]} instead of {reference_num_cols}\")\n",
    "        consistent = False\n",
    "\n",
    "if consistent:\n",
    "    print(\"All S2506 files have the same number of columns and column names (regardless of order).\")\n",
    "else:\n",
    "    print(\"Some S2506 files have inconsistencies in column count or names.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check each year has same number of tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencies in row counts for S2506_06 files:\n",
      "S2506_06_2010.csv: 8058 rows\n",
      "S2506_06_2011.csv: 8059 rows\n",
      "S2506_06_2012.csv: 8058 rows\n",
      "S2506_06_2013.csv: 8058 rows\n",
      "S2506_06_2014.csv: 8058 rows\n",
      "S2506_06_2015.csv: 8058 rows\n",
      "S2506_06_2016.csv: 8058 rows\n",
      "S2506_06_2017.csv: 8058 rows\n",
      "S2506_06_2018.csv: 8058 rows\n",
      "S2506_06_2019.csv: 8058 rows\n",
      "All S2506_32 files have the same number of rows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory\n",
    "cleaned_dir = r\"H:\\GY350\\CSVs Cleaned\"\n",
    "\n",
    "# Store row counts separately for S2506_06 and S2506_32\n",
    "row_counts_06 = {}\n",
    "row_counts_32 = {}\n",
    "\n",
    "# Iterate over S2506 files\n",
    "for filename in os.listdir(cleaned_dir):\n",
    "    if filename.startswith(\"S2506_06\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(cleaned_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            row_counts_06[filename] = len(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    elif filename.startswith(\"S2506_32\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(cleaned_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            row_counts_32[filename] = len(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "# Check for consistency in S2506_06\n",
    "if len(set(row_counts_06.values())) == 1:\n",
    "    print(\"All S2506_06 files have the same number of rows.\")\n",
    "else:\n",
    "    print(\"Inconsistencies in row counts for S2506_06 files:\")\n",
    "    for file, count in row_counts_06.items():\n",
    "        print(f\"{file}: {count} rows\")\n",
    "\n",
    "# Check for consistency in S2506_32\n",
    "if len(set(row_counts_32.values())) == 1:\n",
    "    print(\"All S2506_32 files have the same number of rows.\")\n",
    "else:\n",
    "    print(\"Inconsistencies in row counts for S2506_32 files:\")\n",
    "    for file, count in row_counts_32.items():\n",
    "        print(f\"{file}: {count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for inconsistency with 06_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEO_ID 1400000US06085508704 is missing in years: [2019]\n",
      "GEO_ID 1400000US06053013200 is missing in years: [2018]\n",
      "GEO_ID 1400000US06001400100 is missing in years: [2014]\n",
      "GEO_ID 1400000US06037800204 is missing in years: [2016]\n",
      "GEO_ID 1400000US06073019809 is missing in years: [2012]\n",
      "GEO_ID 1400000US06037930401 is missing in years: [2016, 2017, 2018, 2019, 2012, 2013, 2014, 2015]\n",
      "GEO_ID 1400000US06037137000 is missing in years: [2010]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory\n",
    "cleaned_dir = r\"H:\\GY350\\CSVs Cleaned\"\n",
    "\n",
    "# Store GEO_IDs and Tract values across years\n",
    "yearly_geo_ids = {}\n",
    "yearly_tracts = {}\n",
    "\n",
    "# Iterate through years 2010-2019\n",
    "for year in range(2010, 2020):\n",
    "    file_path = os.path.join(cleaned_dir, f\"S2506_06_{year}.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if \"GEO_ID\" in df.columns:\n",
    "            yearly_geo_ids[year] = set(df[\"GEO_ID\"].dropna())\n",
    "        else:\n",
    "            print(f\"GEO_ID column missing in {year}\")\n",
    "        \n",
    "        if \"Tract\" in df.columns:\n",
    "            yearly_tracts[year] = set(df[\"Tract\"].dropna())\n",
    "        else:\n",
    "            print(f\"Tract column missing in {year}\")\n",
    "\n",
    "# Check for GEO_ID inconsistencies\n",
    "all_years = set(range(2010, 2020))\n",
    "all_geo_ids = set.union(*yearly_geo_ids.values())\n",
    "\n",
    "for geo_id in all_geo_ids:\n",
    "    missing_years = [year for year in all_years if geo_id not in yearly_geo_ids.get(year, set())]\n",
    "    if missing_years:\n",
    "        print(f\"GEO_ID {geo_id} is missing in years: {missing_years}\")\n",
    "\n",
    "# Check for duplicate GEO_IDs in each year\n",
    "for year, geo_ids in yearly_geo_ids.items():\n",
    "    file_path = os.path.join(cleaned_dir, f\"S2506_06_{year}.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    duplicate_count = df[\"GEO_ID\"].duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"Year {year} has {duplicate_count} duplicate GEO_IDs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it was the one which needs to be delted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
